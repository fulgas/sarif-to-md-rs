name: Benchmarks

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  pages: write
  id-token: write

env:
  CARGO_TERM_COLOR: always

jobs:
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6
        with:
          fetch-depth: 0

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        with:
          cache-on-failure: true

      - name: Download previous benchmark results
        uses: actions/cache@9255dc7a253b0ccc959486e2bca901246202afeb # v5
        with:
          path: |
            target/criterion
            benchmark-history
          key: benchmark-cache-${{ github.ref_name }}-${{ github.sha }}
          restore-keys: |
            benchmark-cache-${{ github.ref_name }}-
            benchmark-cache-main-

      - name: Download main branch benchmarks
        if: github.event_name == 'pull_request'
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        with:
          name: main-branch-benchmarks
          path: main-benchmarks
        continue-on-error: true

      - name: Check if benchmarks needed
        id: check
        run: |
          echo "SKIP_BENCHMARKS=false" >> $GITHUB_OUTPUT
          echo "REUSE_MAIN_BENCHMARKS=false" >> $GITHUB_OUTPUT

          if [ "${{ github.event_name }}" = "pull_request" ]; then
            # Check if we have recent main branch benchmarks
            if [ -f "main-benchmarks/benchmark-results.txt" ] && [ -d "main-benchmarks/criterion" ]; then
              echo "âœ… Found cached main branch benchmarks, will reuse them"
              echo "REUSE_MAIN_BENCHMARKS=true" >> $GITHUB_OUTPUT
              echo "NEED_PR_BENCHMARKS=true" >> $GITHUB_OUTPUT
            else
              echo "âš ï¸ No main branch benchmarks found, will run both main and PR benchmarks"
              echo "NEED_PR_BENCHMARKS=true" >> $GITHUB_OUTPUT
            fi
          else
            # For main branch, check if we need to run benchmarks
            CURRENT_COMMIT="${{ github.sha }}"
            if [ -f "benchmark-history/results-$CURRENT_COMMIT.json" ]; then
              echo "âœ… Benchmarks already exist for this commit, skipping"
              echo "SKIP_BENCHMARKS=true" >> $GITHUB_OUTPUT
            else
              echo "ðŸ“Š Running benchmarks for new commit on main"
              echo "NEED_MAIN_BENCHMARKS=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Run main branch baseline (cached or new)
        if: steps.check.outputs.REUSE_MAIN_BENCHMARKS == 'false' && (github.event_name == 'pull_request' || steps.check.outputs.NEED_MAIN_BENCHMARKS == 'true')
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            # Switch to main branch for baseline
            git fetch origin main:main
            git checkout main
            echo "ðŸ”„ Running main branch benchmarks (this will be cached for future PRs)..."
            cargo bench --bench benchmarks -- --save-baseline main | tee main-benchmark-results.txt
            mkdir -p main-benchmarks
            cp main-benchmark-results.txt main-benchmarks/benchmark-results.txt
            cp -r target/criterion main-benchmarks/criterion
            git checkout ${{ github.event.pull_request.head.sha }}
          else
            echo "ðŸ“Š Running main branch benchmarks..."
            cargo bench --bench benchmarks | tee benchmark-results.txt
          fi

      - name: Run PR benchmarks and comparison
        if: steps.check.outputs.NEED_PR_BENCHMARKS == 'true' && steps.check.outputs.SKIP_BENCHMARKS == 'false'
        run: |
          echo "ðŸ” Running PR benchmarks and comparing against main..."

          # Load main branch baseline
          if [ "${{ steps.check.outputs.REUSE_MAIN_BENCHMARKS }}" = "true" ]; then
            echo "Using cached main branch benchmarks"
            cp -r main-benchmarks/criterion/* target/criterion/
            # Extract baseline from cached results
            cargo bench --bench benchmarks -- --load-baseline main | tee pr-benchmark-results.txt || true
          fi

          # Run PR benchmarks with comparison
          cargo bench --bench benchmarks -- --baseline main | tee benchmark-results.txt

          # Save comparison summary
          if grep -q "change:" benchmark-results.txt; then
            echo "PERFORMANCE_CHANGES_DETECTED=true" >> $GITHUB_ENV
            grep -A2 -B2 "change:" benchmark-results.txt > benchmark-summary.txt
          else
            echo "PERFORMANCE_CHANGES_DETECTED=false" >> $GITHUB_ENV
          fi

      - name: Process main branch results
        if: github.ref == 'refs/heads/main' && steps.check.outputs.SKIP_BENCHMARKS == 'false'
        run: |
          echo "ðŸ“Š Processing main branch benchmark results..."

          # Save current results for future comparisons
          CURRENT_COMMIT="${{ github.sha }}"
          mkdir -p benchmark-history
          cp -r target/criterion benchmark-history/criterion-$CURRENT_COMMIT

          # Extract key metrics to a JSON file
          cat > benchmark-history/results-$CURRENT_COMMIT.json << EOF
          {
            "commit": "$CURRENT_COMMIT",
            "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "branch": "${{ github.ref_name }}"
          }
          EOF


      - name: Upload main branch benchmarks as artifact
        if: github.ref == 'refs/heads/main' && steps.check.outputs.SKIP_BENCHMARKS == 'false'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: main-branch-benchmarks
          path: |
            benchmark-results.txt
            target/criterion
          retention-days: 30
          overwrite: true

      - name: Upload Criterion reports separately for pages
        if: github.ref == 'refs/heads/main' && steps.check.outputs.SKIP_BENCHMARKS == 'false'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: criterion-reports
          path: target/criterion
          retention-days: 7
          overwrite: true


      - name: Generate benchmark summary for PR
        if: github.event_name == 'pull_request'
        run: |
          echo "## ðŸ“Š Performance Benchmark Results vs Main Branch" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check if we have performance changes
          if [ "$PERFORMANCE_CHANGES_DETECTED" = "true" ] && [ -f "benchmark-summary.txt" ]; then
            echo "### ðŸ” Performance Changes Detected" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`diff" >> $GITHUB_STEP_SUMMARY
            cat benchmark-summary.txt >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

            # Add interpretation
            if grep -qi "faster\|improved" benchmark-summary.txt; then
              echo "âœ… **Overall performance improvement detected!**" >> $GITHUB_STEP_SUMMARY
            elif grep -qi "slower\|regression" benchmark-summary.txt; then
              echo "âš ï¸ **Performance regression detected - please review**" >> $GITHUB_STEP_SUMMARY
            else
              echo "â„¹ï¸ **Mixed performance changes - review individual benchmarks**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âœ… **No significant performance changes detected**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Performance is stable compared to main branch." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View detailed benchmark reports](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/)"

      - name: Generate benchmark summary for main branch
        if: github.ref == 'refs/heads/main'
        run: |
          echo "## ðŸ“Š Performance Tracking Update" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Benchmark results for commit \`${{ github.sha }}\` have been recorded." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Show performance status
          if [ "$PERFORMANCE_REGRESSION" = "true" ]; then
            echo "âš ï¸ **Performance Regression Alert**" >> $GITHUB_STEP_SUMMARY
            echo "This commit introduced performance regressions. Please investigate." >> $GITHUB_STEP_SUMMARY
          elif [ "$PERFORMANCE_IMPROVEMENT" = "true" ]; then
            echo "ðŸš€ **Performance Improvement**" >> $GITHUB_STEP_SUMMARY
            echo "Great! This commit improved performance." >> $GITHUB_STEP_SUMMARY
          else
            echo "âœ… **Performance Stable**" >> $GITHUB_STEP_SUMMARY
            echo "No significant performance changes detected." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Historical Tracking" >> $GITHUB_STEP_SUMMARY
          echo "- Results saved for future commit comparisons" >> $GITHUB_STEP_SUMMARY
          echo "- Available for PR baseline comparisons" >> $GITHUB_STEP_SUMMARY
          echo "- Historical trends published to GitHub Pages" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— [View performance dashboard](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/)"



  deploy-pages-content:
    name: Generate GitHub Pages
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    needs: benchmark

    steps:
      - name: Checkout repository
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6

      - name: Download main benchmark results
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        with:
          name: main-branch-benchmarks
          path: main-benchmarks
        continue-on-error: true

      - name: Download Criterion reports
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7
        with:
          name: criterion-reports
          path: criterion-reports
        continue-on-error: true

      - name: Prepare pages content
        run: |
          mkdir -p pages-content

          # Copy Criterion reports if available
          if [ -d "criterion-reports" ]; then
            echo "ðŸ“Š Copying Criterion reports..."
            cp -r criterion-reports pages-content/criterion
          elif [ -d "main-benchmarks/criterion" ]; then
            echo "ðŸ“Š Copying Criterion reports from main benchmarks fallback..."
            cp -r main-benchmarks/criterion pages-content/
          else
            echo "âš ï¸ No Criterion reports found, creating empty directory"
            mkdir -p pages-content/criterion
          fi


      - name: Install pandoc for markdown conversion
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc

      - name: Generate index page content
        run: |
          # Create index markdown content
          cat > pages-content/index.md << EOF
          ---
          title: "SARIF to Markdown Performance Dashboard"
          ---

          <div class="header-info">
          Updated $(date +"%B %d, %Y")<br>
          <a href="https://github.com/${{ github.repository }}">${{ github.repository }}</a>
          </div>

          ## Performance Benchmarks

          - [Core Generation](criterion/core_generation/report/) - Comprehensive format and option testing
          - [File Processing](criterion/file_processing/report/) - End-to-end processing pipeline
          - [Memory Usage](criterion/memory_usage/large_file_processing/report/) - Memory efficiency with large files
          - [Output Formats](criterion/output_formats/report/) - Format comparison (CommonMark vs GitHub)
          - [SARIF Complexity](criterion/sarif_complexity/report/) - Complex SARIF feature handling


          ---

          ## Links

          - [Source Repository](https://github.com/${{ github.repository }})
          - [CI Workflow](https://github.com/${{ github.repository }}/actions/workflows/benchmarks.yml)
          - [Releases](https://github.com/${{ github.repository }}/releases)
          - [Crates.io Package](https://crates.io/crates/sarif-to-md)

          EOF

          # Create shared CSS for both index and comparison pages
          cat > pages-content/shared-style.css << 'EOF'
          body {
            font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;
            margin: 0;
            padding: 60px 40px;
            background-color: #ffffff;
            color: #333333;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
          }
          h1 {
            color: #000000;
            font-size: 2em;
            font-weight: 300;
            margin-bottom: 2em;
            text-align: center;
            letter-spacing: -0.5px;
          }
          h2 {
            color: #333333;
            font-size: 1.2em;
            font-weight: 400;
            margin: 3em 0 1em 0;
            border-left: 3px solid #000000;
            padding-left: 1em;
          }
          h3 {
            color: #555555;
            font-size: 1em;
            font-weight: 400;
            margin: 2em 0 1em 0;
          }
          a {
            color: #000000;
            text-decoration: none;
            border-bottom: 1px solid #cccccc;
            transition: border-bottom-color 0.2s;
          }
          a:hover { border-bottom-color: #000000; }
          ul {
            list-style: none;
            padding: 0;
          }
          li {
            margin: 0.8em 0;
            padding-left: 2em;
            position: relative;
          }
          li:before {
            content: "â†’";
            position: absolute;
            left: 0;
            color: #666666;
          }
          .header-info {
            text-align: center;
            color: #666666;
            font-size: 0.9em;
            margin-bottom: 4em;
          }
          hr {
            border: none;
            border-top: 1px solid #e0e0e0;
            margin: 4em 0;
          }
          p { margin: 1em 0; }
          strong { font-weight: 600; }

          /* Table styles for comparison page */
          table {
            width: 100%;
            border-collapse: collapse;
            margin: 2em 0;
            font-size: 0.9em;
          }
          th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
          }
          th {
            background-color: #f8f8f8;
            font-weight: 600;
            color: #000000;
          }
          tr:hover {
            background-color: #f9f9f9;
          }
          .back-link {
            display: inline-block;
            margin-bottom: 2em;
            padding: 0.5em 1em;
            border: 1px solid #e0e0e0;
            background-color: #f8f8f8;
            text-decoration: none;
          }

          EOF

          # Convert index markdown to HTML
          pandoc pages-content/index.md \
            --from markdown \
            --to html5 \
            --css shared-style.css \
            --standalone \
            --output pages-content/index.html


      - name: Upload combined results
        uses: actions/upload-pages-artifact@7b1f4a764d45c48632c6b24a0339c27f5614fb0b # v4
        with:
          path: pages-content

  deploy-pages:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    needs: deploy-pages-content

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4